{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f90f12-9356-438f-bb30-80ff5d9f4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "os.chdir('../')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, BertTokenizer\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from utils.forward_fn import forward_sequence_classification\n",
    "from utils.metrics import document_sentiment_metrics_fn\n",
    "from utils.data_utils_kazee3 import DocumentSentimentDataset, DocumentSentimentDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e221bc2f-f001-44e9-8810-8c2eed314266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? True\n",
      "Device count? 4\n",
      "Current device? 0\n",
      "Device name?  NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Is cuda available?\", torch.cuda.is_available())\n",
    "print(\"Device count?\", torch.cuda.device_count())\n",
    "print(\"Current device?\", torch.cuda.current_device())\n",
    "print(\"Device name? \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1856e8e1-e8d2-4f5e-9436-17b58ccc2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ff7933-68ab-4b9c-8f7f-25c652f7b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def metrics_to_string(metric_dict):\n",
    "    string_list = []\n",
    "    for key, value in metric_dict.items():\n",
    "        string_list.append('{}:{:.2f}'.format(key, value))\n",
    "    return ' '.join(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7b532b-ba76-4d13-adc6-48148a0fa3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(25072024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49a96e-a4ab-473e-9a11-c91d6716b600",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c86317-e0ca-410e-b3b4-16332cc89113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = 'indobenchmark/indobert-lite-large-p1'\n",
    "base_model = './dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/save_model/sent_statement_llp2_240724'\n",
    "model_save = './dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/save_model/sent_statement_llp2_240724'\n",
    "\n",
    "train_dataset_path = './dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/data_train/train_data_statement.tsv'\n",
    "valid_dataset_path = './dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/data_train/valid_data_statement_baru.tsv'\n",
    "test_dataset_path = './dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/data_train/test_data_statement_baru.tsv'\n",
    "# test_dataset_path = './dataset/ormrev/test_news.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d63f9b-aeed-4a4b-a298-d023642d983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_dataset_path, sep='\\t', header=None)\n",
    "train.columns = ['statements', 'sentiment']\n",
    "valid = pd.read_csv(valid_dataset_path, sep='\\t', header=None)\n",
    "valid.columns = ['statements', 'sentiment']\n",
    "test = pd.read_csv(test_dataset_path, sep='\\t', header=None)\n",
    "test.columns = ['statements', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6aa9fb-e578-409b-902a-8e8c0df4c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1256 entries, 0 to 1255\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   statements  1256 non-null   object\n",
      " 1   sentiment   1256 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 19.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5ae915-b777-4efd-9842-0a85c9a4fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157 entries, 0 to 156\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   statements  157 non-null    object\n",
      " 1   sentiment   157 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0201213-de40-4663-a464-92242c4201c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   statements  158 non-null    object\n",
      " 1   sentiment   158 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384b0209-f2fc-4850-97cf-108ea1cbd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(base_model)\n",
    "config = AutoConfig.from_pretrained(base_model)\n",
    "config.num_labels = DocumentSentimentDataset.NUM_LABELS\n",
    "\n",
    "# Instantiate model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369073ea-8dcd-4a47-baa0-6d82a08f3db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=1024, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (ffn_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "746eda34-b163-4868-a607-e1486460d611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17687043"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f6c429d-46b6-4a15-b342-e3d31f4ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DocumentSentimentDataset(\n",
    "    train_dataset_path, tokenizer, lowercase=True)\n",
    "valid_dataset = DocumentSentimentDataset(\n",
    "    valid_dataset_path, tokenizer, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fd47aac-29f9-4dce-8fca-c9c489d34275",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DocumentSentimentDataLoader(\n",
    "    dataset=train_dataset, max_seq_len=512, batch_size=16, num_workers=2, shuffle=True)\n",
    "valid_loader = DocumentSentimentDataLoader(\n",
    "    dataset=valid_dataset, max_seq_len=512, batch_size=8, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6549ff4b-b0a6-4c75-b32a-ba7867bbb3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0, 'neutral': 1, 'negative': 2}\n",
      "{0: 'positive', 1: 'neutral', 2: 'negative'}\n"
     ]
    }
   ],
   "source": [
    "w2i, i2w = DocumentSentimentDataset.LABEL2INDEX, DocumentSentimentDataset.INDEX2LABEL\n",
    "print(w2i)\n",
    "print(i2w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d67ded-d0b7-4bf0-8a37-ac459277fac9",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b9b3ebd-8967-4fbe-8095-bcb05247959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-6)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c795a246-7583-4a2a-99e3-29dc55171de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:0.0269 LR:0.00000200: 100%|██████████| 314/314 [00:39<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:0.0269 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8293 ACC:0.83 F1:0.82 REC:0.82 PRE:0.83: 100%|██████████| 20/20 [00:01<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) VALID LOSS:0.8293 ACC:0.83 F1:0.82 REC:0.82 PRE:0.83\n",
      "current best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:0.0211 LR:0.00000200: 100%|██████████| 314/314 [00:36<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:0.0211 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8866 ACC:0.79 F1:0.79 REC:0.81 PRE:0.81: 100%|██████████| 20/20 [00:01<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) VALID LOSS:0.8866 ACC:0.79 F1:0.79 REC:0.81 PRE:0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:0.0204 LR:0.00000200: 100%|██████████| 314/314 [00:33<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:0.0204 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.7094 ACC:0.83 F1:0.82 REC:0.82 PRE:0.84: 100%|██████████| 20/20 [00:01<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) VALID LOSS:0.7094 ACC:0.83 F1:0.82 REC:0.82 PRE:0.84\n",
      "current best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:0.0205 LR:0.00000200: 100%|██████████| 314/314 [00:35<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:0.0205 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.6510 ACC:0.83 F1:0.83 REC:0.82 PRE:0.84: 100%|██████████| 20/20 [00:02<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) VALID LOSS:0.6510 ACC:0.83 F1:0.83 REC:0.82 PRE:0.84\n",
      "current best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:0.0187 LR:0.00000200: 100%|██████████| 314/314 [00:35<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:0.0187 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.7724 ACC:0.80 F1:0.81 REC:0.82 PRE:0.82: 100%|██████████| 20/20 [00:01<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) VALID LOSS:0.7724 ACC:0.80 F1:0.81 REC:0.82 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 6) TRAIN LOSS:0.0193 LR:0.00000200: 100%|██████████| 314/314 [00:35<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6) TRAIN LOSS:0.0193 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.6824 ACC:0.83 F1:0.83 REC:0.83 PRE:0.83: 100%|██████████| 20/20 [00:01<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6) VALID LOSS:0.6824 ACC:0.83 F1:0.83 REC:0.83 PRE:0.83\n",
      "current best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 7) TRAIN LOSS:0.0204 LR:0.00000200: 100%|██████████| 314/314 [00:38<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7) TRAIN LOSS:0.0204 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.6581 ACC:0.87 F1:0.86 REC:0.87 PRE:0.86: 100%|██████████| 20/20 [00:02<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7) VALID LOSS:0.6581 ACC:0.87 F1:0.86 REC:0.87 PRE:0.86\n",
      "current best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 8) TRAIN LOSS:0.0177 LR:0.00000200: 100%|██████████| 314/314 [00:32<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8) TRAIN LOSS:0.0177 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.7620 ACC:0.85 F1:0.85 REC:0.86 PRE:0.84: 100%|██████████| 20/20 [00:02<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8) VALID LOSS:0.7620 ACC:0.85 F1:0.85 REC:0.86 PRE:0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 9) TRAIN LOSS:0.0186 LR:0.00000200: 100%|██████████| 314/314 [00:33<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9) TRAIN LOSS:0.0186 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.6683 ACC:0.86 F1:0.86 REC:0.86 PRE:0.85: 100%|██████████| 20/20 [00:01<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9) VALID LOSS:0.6683 ACC:0.86 F1:0.86 REC:0.86 PRE:0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 10) TRAIN LOSS:0.0191 LR:0.00000200: 100%|██████████| 314/314 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10) TRAIN LOSS:0.0191 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.6872 ACC:0.85 F1:0.84 REC:0.85 PRE:0.84: 100%|██████████| 20/20 [00:02<00:00,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10) VALID LOSS:0.6872 ACC:0.85 F1:0.84 REC:0.85 PRE:0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "n_epochs = 10\n",
    "best_f1 = 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    total_train_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
    "    for i, batch_data in enumerate(train_pbar):\n",
    "        # Forward model\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(\n",
    "            model, batch_data[:-1], i2w=i2w, device='cuda')\n",
    "\n",
    "        # Update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss = loss.item()\n",
    "        total_train_loss = total_train_loss + tr_loss\n",
    "\n",
    "        # Calculate metrics\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "\n",
    "        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch + 1),\n",
    "                                                                                   total_train_loss / (i + 1), get_lr(optimizer)))\n",
    "\n",
    "    # Calculate train metric\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch + 1),\n",
    "                                                             total_train_loss / (i + 1), metrics_to_string(metrics), get_lr(optimizer)))\n",
    "\n",
    "    # Evaluate on validation\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_loss, total_correct, total_labels = 0, 0, 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
    "    for i, batch_data in enumerate(pbar):\n",
    "        batch_seq = batch_data[-1]\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(\n",
    "            model, batch_data[:-1], i2w=i2w, device='cuda')\n",
    "\n",
    "        # Calculate total loss\n",
    "        valid_loss = loss.item()\n",
    "        total_loss = total_loss + valid_loss\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "\n",
    "        pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(\n",
    "            total_loss / (i + 1), metrics_to_string(metrics)))\n",
    "\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch + 1),\n",
    "                                                   total_loss / (i + 1), metrics_to_string(metrics)))\n",
    "\n",
    "    if metrics['F1'] > best_f1:\n",
    "        best_f1 = metrics['F1']\n",
    "        model.save_pretrained(model_save)\n",
    "        tokenizer.save_pretrained(model_save)\n",
    "        config.save_pretrained(model_save)\n",
    "\n",
    "        print('current best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c6733d9-2f00-4ee3-a68a-0dc16eb90c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:0.0191 LR:0.00000200: 100%|██████████| 79/79 [00:25<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:0.0191 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.7894 ACC:0.83 F1:0.82 REC:0.82 PRE:0.83: 100%|██████████| 20/20 [00:02<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) VALID LOSS:0.7894 ACC:0.83 F1:0.82 REC:0.82 PRE:0.83\n",
      "current best\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.85      0.90      0.87        73\n",
      "     neutral       0.76      0.74      0.75        42\n",
      "    negative       0.89      0.81      0.85        42\n",
      "\n",
      "    accuracy                           0.83       157\n",
      "   macro avg       0.83      0.82      0.82       157\n",
      "weighted avg       0.84      0.83      0.83       157\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:0.0191 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:0.0191 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8080 ACC:0.83 F1:0.82 REC:0.82 PRE:0.82: 100%|██████████| 20/20 [00:01<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) VALID LOSS:0.8080 ACC:0.83 F1:0.82 REC:0.82 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:0.0175 LR:0.00000200: 100%|██████████| 79/79 [00:24<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:0.0175 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8380 ACC:0.82 F1:0.81 REC:0.81 PRE:0.82: 100%|██████████| 20/20 [00:01<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) VALID LOSS:0.8380 ACC:0.82 F1:0.81 REC:0.81 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:0.0182 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:0.0182 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8313 ACC:0.83 F1:0.82 REC:0.82 PRE:0.82: 100%|██████████| 20/20 [00:02<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) VALID LOSS:0.8313 ACC:0.83 F1:0.82 REC:0.82 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:0.0172 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:0.0172 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8829 ACC:0.82 F1:0.82 REC:0.83 PRE:0.82: 100%|██████████| 20/20 [00:02<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) VALID LOSS:0.8829 ACC:0.82 F1:0.82 REC:0.83 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 6) TRAIN LOSS:0.0171 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6) TRAIN LOSS:0.0171 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8455 ACC:0.83 F1:0.82 REC:0.81 PRE:0.83: 100%|██████████| 20/20 [00:01<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6) VALID LOSS:0.8455 ACC:0.83 F1:0.82 REC:0.81 PRE:0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 7) TRAIN LOSS:0.0180 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7) TRAIN LOSS:0.0180 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8865 ACC:0.82 F1:0.82 REC:0.83 PRE:0.82: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7) VALID LOSS:0.8865 ACC:0.82 F1:0.82 REC:0.83 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 8) TRAIN LOSS:0.0165 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8) TRAIN LOSS:0.0165 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.9744 ACC:0.80 F1:0.80 REC:0.81 PRE:0.80: 100%|██████████| 20/20 [00:01<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8) VALID LOSS:0.9744 ACC:0.80 F1:0.80 REC:0.81 PRE:0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 9) TRAIN LOSS:0.0175 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9) TRAIN LOSS:0.0175 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8405 ACC:0.82 F1:0.81 REC:0.81 PRE:0.82: 100%|██████████| 20/20 [00:02<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9) VALID LOSS:0.8405 ACC:0.82 F1:0.81 REC:0.81 PRE:0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 10) TRAIN LOSS:0.0176 LR:0.00000200: 100%|██████████| 79/79 [00:23<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10) TRAIN LOSS:0.0176 ACC:0.99 F1:0.99 REC:0.99 PRE:0.99 LR:0.00000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:0.8639 ACC:0.83 F1:0.82 REC:0.82 PRE:0.83: 100%|██████████| 20/20 [00:01<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10) VALID LOSS:0.8639 ACC:0.83 F1:0.82 REC:0.82 PRE:0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fungsi untuk menghitung dan menampilkan classification report\n",
    "def display_classification_report(list_hyp, list_label):\n",
    "    list_hyp_idx = [DocumentSentimentDataset.LABEL2INDEX[hyp] for hyp in list_hyp]\n",
    "    list_label_idx = [DocumentSentimentDataset.LABEL2INDEX[label] for label in list_label]\n",
    "    \n",
    "    target_names = [DocumentSentimentDataset.INDEX2LABEL[i] for i in range(DocumentSentimentDataset.NUM_LABELS)]\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(list_label_idx, list_hyp_idx, target_names=target_names))\n",
    "\n",
    "# Train\n",
    "n_epochs = 10\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    total_train_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
    "    for i, batch_data in enumerate(train_pbar):\n",
    "        # Forward model\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
    "\n",
    "        # Update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss = loss.item()\n",
    "        total_train_loss += tr_loss\n",
    "\n",
    "        # Calculate metrics\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "\n",
    "        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch + 1),\n",
    "                                                                                   total_train_loss / (i + 1), get_lr(optimizer)))\n",
    "\n",
    "    # Calculate train metric\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch + 1),\n",
    "                                                             total_train_loss / (i + 1), metrics_to_string(metrics), get_lr(optimizer)))\n",
    "\n",
    "    # Evaluate on validation\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_loss, total_correct, total_labels = 0, 0, 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
    "    for i, batch_data in enumerate(pbar):\n",
    "        batch_seq = batch_data[-1]\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
    "\n",
    "        # Calculate total loss\n",
    "        valid_loss = loss.item()\n",
    "        total_loss += valid_loss\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "\n",
    "        pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(\n",
    "            total_loss / (i + 1), metrics_to_string(metrics)))\n",
    "\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch + 1),\n",
    "                                                   total_loss / (i + 1), metrics_to_string(metrics)))\n",
    "\n",
    "    if metrics['F1'] > best_f1:\n",
    "        best_f1 = metrics['F1']\n",
    "        model.save_pretrained(model_save)\n",
    "        tokenizer.save_pretrained(model_save)\n",
    "        config.save_pretrained(model_save)\n",
    "\n",
    "        print('current best')\n",
    "        # Display classification report for the current best model\n",
    "        display_classification_report(list_hyp, list_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c517385b-1ad2-4a76-84ec-6a636027c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/data_train/valid_data_statement_baru_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b379ff-1168-4bca-8531-0838e62c7550",
   "metadata": {},
   "source": [
    "## Test Model for Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e6ee6d3-9380-476a-b061-c806d57df117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: polri bertugas secara profesional dan tak pandang bulu. | Label : positive (99.949%)\n"
     ]
    }
   ],
   "source": [
    "text = 'polri bertugas secara profesional dan tak pandang bulu.'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(\n",
    "    f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e36681fa-faec-4120-927a-b1fc41364193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: semuanya masih proses awal belum masuk dalam rapat dpp dan belum dilaporkan kepada ibu ketua umum | Label : neutral (99.986%)\n"
     ]
    }
   ],
   "source": [
    "text = 'semuanya masih proses awal belum masuk dalam rapat dpp dan belum dilaporkan kepada ibu ketua umum'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(\n",
    "    f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "769ce003-7841-421d-982e-ce8d6a7d383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: enggak ada ancaman, cuman dibilangnya percuma punya teman punya saudara jadi pj gubernur, tapi gak ada gunanya | Label : negative (99.972%)\n"
     ]
    }
   ],
   "source": [
    "text = 'enggak ada ancaman, cuman dibilangnya percuma punya teman punya saudara jadi pj gubernur, tapi gak ada gunanya'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(\n",
    "    f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25014142-274c-4f7d-b946-ba4dcf32617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model = './dataset/emot_emotion-twitter/dataset_smsa_sentiments_kazee/save_model/sent_statement_llp2_240724_acc86'\n",
    "model.save_pretrained(model_save)\n",
    "tokenizer.save_pretrained(model_save)\n",
    "config.save_pretrained(model_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b5a6e-e8e3-4a85-a45c-60ac99519570",
   "metadata": {},
   "source": [
    "## TEST FOR DATA TEST_SENTIMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
